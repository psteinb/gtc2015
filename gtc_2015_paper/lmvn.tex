\documentclass [12pt]{article}
\usepackage{url}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\include{listing_style}
\def \fftw {\texttt{fftw}}
\def \cufft {\texttt{cufft}}
\def \gpu {GPGPU}
\def \cpu {CPU}

\title{Streaming FFTs on large 3D microscope image data}
\author{Peter Steinbach, MPI CBG}
%\institute{MPI CBG}
\begin{document}
\maketitle
\begin{abstract}

\end{abstract}

\section{Introduction}

Light sheet microscopy today has become the hallmark experimental technique of systems biology \cite{Huisken13082004, Keller14112008}. It allows image aquisition of large alive developing specimens, high temporal and spatial resolution, imaging from multiple angles as well as low photodamage to the specimen which enables long timelapse recordings. However, due to the limited optical performance of the used equipment and the constant tradeoff between acquisition frequency and resolution, segmenting the produced data for further analysis is challenging. Deconvolution is the operation of restoring spatial resolution and contrast of this data given the knowledge of the underlying optics after the imagery has been recorded. Here, Selective Plane Illumination Microscopy (SPIM) data offers high potentials for SPIM records the same geometric location from different angles.\newline

The authors of \cite{2013arXiv1308.0730P} have provided an optimized formulation of the iterative expectation-maximization algorithm used to deconvolve SPIM data. This implementation thereof \cite{gh_spim_registration} is the starting point for this study whose motivation is to further increase performance and turnover of the algorithm by porting it entirely to run on General Purpose Graphics Processing Units (GPGPUs) using the CUDA programming platform \cite{Nickolls:2008:CUDA}. The implementation is available as a free and open-source library from \cite{lmvn_repo}.\newline

For the purpose of this paper, the subsequent discussion will first discuss the current algorithm implementation and common usage patterns(section \ref{sec:alg}), followed by a brief description of the benchmark hardware (section \ref{sec:hw}). The focus of the paper will then be on developing a performant implementation through a bottoms-up approach using model implementations (section \ref{}), before concluding with a summary and outlook (section \ref{sec:summ}).\newline

\section[sec:alg]{Algorithm Details and Usage}
\include{algorithm}

\clearpage
\section[sec:hw]{Hardware}

For the measurements at hand, a Dell T7810 work station was used equipped with two Intel Xeon E5-2540 v3 processors and 64 GB of DDR4-2133 RAM. The workstation supported a Nvidia Tesla K20c provided by the TU Dresden based CUDA Center Of Excellence. The operating system was CentOS 7. To broaden the scope, a passively cooled Nvidia Tesla M2090 operated inside a rack-mounted Dell C6100 with two E5-2640 and 128 GB of RAM. The operating system was CentOS 6.3 and all compilations were performed with gcc 4.8.3 and cuda 6.5. All compilations were performed with gcc 4.8.3 and cuda 6.5 except stated otherwise.

\section[sec:models]{Model}

\include{models}

\section[sec:summ]{Summary}


\section{References}
\bibliographystyle{ieeetr}
\bibliography{lmvn}
\end{document}
