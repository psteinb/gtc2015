\documentclass [a4paper,12pt]{article}
\usepackage{url}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{units}
\usepackage{fullpage}

\include{listing_style}
\def \fftw {\texttt{fftw}}
\def \lmvn {\texttt{libmultiviewnative}}
\def \cufft {\texttt{cufft}}
\def \gpu {GPGPU}
\def \cpu {CPU}

\title{Streaming FFTs on large 3D microscope image data}
\author{Peter Steinbach, MPI CBG}
%\institute{MPI CBG}
\begin{document}
\maketitle
\begin{abstract}

\end{abstract}

\section{Introduction}

Light sheet microscopy today has become the hallmark experimental technique of systems biology \cite{Huisken13082004, Keller14112008}. It allows image aquisition of large alive developing specimens, high temporal and spatial resolution, imaging from multiple angles as well as low photodamage to the specimen which enables long timelapse recordings. However, due to the limited optical performance of the used equipment and the constant tradeoff between acquisition frequency and resolution, segmenting the produced data for further analysis is challenging. Deconvolution is the operation of restoring spatial resolution and contrast of this data given the knowledge of the underlying optics after the imagery has been recorded. Here, Selective Plane Illumination Microscopy (SPIM) data offers high potentials for SPIM records the same geometric location from different angles.\newline

The authors of \cite{2013arXiv1308.0730P} have provided an optimized formulation of the iterative expectation-maximization algorithm used to deconvolve SPIM data. This implementation thereof \cite{gh_spim_registration} is the starting point for this study whose motivation is to further increase performance and turnover of the algorithm by porting it entirely to run on General Purpose Graphics Processing Units (GPGPUs) using the CUDA programming platform \cite{Nickolls:2008:CUDA}. The implementation is available as a free and open-source library from \cite{lmvn_repo}.\newline

For the purpose of this paper, the subsequent discussion will first discuss the current algorithm implementation and common usage patterns(section \ref{sec:alg}), followed by a brief description of the benchmark hardware (section \ref{sec:hw}). The focus of the paper will then be on developing a performant implementation through a bottoms-up approach using model implementations (section \ref{sec:models}), before concluding with a summary and outlook (section \ref{sec:summ}).\newline

\section{Algorithm Details and Usage}
\label{sec:alg}
\include{algorithm}

\clearpage
\section{Hardware}
\label{sec:hw}

For the measurements at hand, a Dell T7810 work station was used equipped with two Intel Xeon E5-2540 v3 processors and $\unit[64]{GB}$ of DDR4-2133 RAM. The workstation supported a Nvidia Tesla K20c provided by the TU Dresden based CUDA Center Of Excellence. The operating system was CentOS 7. To broaden the scope, a passively cooled Nvidia Tesla M2090 operated inside a rack-mounted Dell C6100 with two Intel Xeon E5-2640 and $\unit[128]{GB}$ of RAM. The operating system was CentOS 6.3 and all compilations were performed with gcc 4.8.3 and cuda 6.5. All compilations were performed with gcc 4.8.3 and cuda 6.5.14 except stated otherwise. Third, a second Dell T7810 work station with 2 Intel Xeon E5-2670 (Hyperthreading enabled), $\unit[64]{GB}$ of DDR4-2133 RAM and a Nvidia GeForce GTX Titan Black running CentOS 6.6 was included in the tests.

\section{Model}
\label{sec:models}

\include{models}

\clearpage

\section{Summary}
\label{sec:summ}

Multiview Deconvolution is a central technique for contrast enhancements of multi-dimensional SPIM data. As the data is of unprecedented size, porting suche an algorithm onto massively parallel hardware (\gpu{}s) requires a constant struggle against data transfer bottlenecks. As such, the PCI Express is the everlasting hurdle to overcome by asynchronous orchestration of memory transfers to the \gpu{} and computing calls. In this study, performance considerations for model systems very similar to the environment of \lmvn{} lead to an improvement of the actual algorithm and a speed-up of $7x$ compared to a state-of-the-art multi-\cpu{} implementation.\newline


\section{Acknowledgements}
\label{sec:ackn}

I'd like to thank Stephan Preibisch (Janelia Farm) and Pavel Tomanck (MPI CBG) for providing me this challenging project that lead me to present at an internationally renowned conference. I'd also like to thank Stephan Janosch for providing test data sets and the CUDA Center of Excellence for providing the Nvidia Tesla K20c used for the experiments above as well as valuable feedback during this project. 

\section{References}
\bibliographystyle{ieeetr}
\bibliography{lmvn}
\end{document}
